{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: einops in ./.local/lib/python3.9/site-packages (0.7.0)\n",
      "Requirement already satisfied: transformers==4.35.2 in ./.local/lib/python3.9/site-packages (4.35.2)\n",
      "Requirement already satisfied: more_itertools in /usr/lib/python3/dist-packages (4.2.0)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.9/site-packages (from transformers==4.35.2) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in ./.local/lib/python3.9/site-packages (from transformers==4.35.2) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.9/site-packages (from transformers==4.35.2) (1.23.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.9/site-packages (from transformers==4.35.2) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.local/lib/python3.9/site-packages (from transformers==4.35.2) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.9/site-packages (from transformers==4.35.2) (2022.10.31)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.9/site-packages (from transformers==4.35.2) (2.28.2)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./.local/lib/python3.9/site-packages (from transformers==4.35.2) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./.local/lib/python3.9/site-packages (from transformers==4.35.2) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.local/lib/python3.9/site-packages (from transformers==4.35.2) (4.64.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.9/site-packages (from requests->transformers==4.35.2) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers==4.35.2) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.local/lib/python3.9/site-packages (from requests->transformers==4.35.2) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers==4.35.2) (2019.11.28)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install einops transformers==4.35.2 more_itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor, tensor, arange, randn, randint, tril, where, ones, allclose, empty, zeros, inference_mode, no_grad, Storage, FloatTensor\n",
    "from torch.nn import Module, Linear, GELU, ReLU, Parameter, Embedding, ModuleList, LayerNorm, MSELoss, KLDivLoss\n",
    "from torch.nn.functional import softmax, cross_entropy\n",
    "from torch.nn.init import zeros_\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from datasets import load_dataset, load_from_disk\n",
    "# from transformer_lens import HookedTransformer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import pickle\n",
    "from dataclasses import dataclass\n",
    "from copy import copy\n",
    "from typing import Optional, Tuple, Union, Dict, Callable, Iterable, Any\n",
    "from einops import einsum\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import isfile\n",
    "from os import remove\n",
    "from math import sqrt, pi, prod\n",
    "from more_itertools import pairwise\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"using\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TransformerConfig:\n",
    "    vocab_size: int\n",
    "    ncontext: int\n",
    "    dmodel: int\n",
    "    dhead: int\n",
    "    nhead: int\n",
    "    dmlp : int\n",
    "    nlayers: int\n",
    "    activation_function: Union[Callable, str] = GELU()\n",
    "    mask_value: float = 1e-5\n",
    "    attention_scale: float = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.attention_scale is None:\n",
    "            self.attention_scale = 1 / sqrt(self.dhead)\n",
    "\n",
    "# copy pasted from https://github.com/huggingface/transformers/blob/main/src/transformers/activations.py\n",
    "class NewGELUActivation(Module):\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        return 0.5 * input * (1.0 + torch.tanh(sqrt(2.0 / pi) * (input + 0.044715 * torch.pow(input, 3.0))))\n",
    "\n",
    "class MLP(Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.up = Linear(cfg.dmodel, cfg.dmlp)\n",
    "        self.down = Linear(cfg.dmlp, cfg.dmodel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.up(x)\n",
    "        x = self.cfg.activation_function(x)\n",
    "        x = self.down(x)\n",
    "        return x\n",
    "\n",
    "class Attention(Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cfg = cfg\n",
    "\n",
    "        self.query_weight  = Parameter(randn(cfg.nhead, cfg.dmodel, cfg.dhead) / sqrt(cfg.dmodel))\n",
    "        self.key_weight    = Parameter(randn(cfg.nhead, cfg.dmodel, cfg.dhead) / sqrt(cfg.dmodel))\n",
    "        self.value_weight  = Parameter(randn(cfg.nhead, cfg.dmodel, cfg.dhead) / sqrt(cfg.dmodel))\n",
    "        self.output_weight = Parameter(randn(cfg.nhead, cfg.dhead, cfg.dmodel) / sqrt(cfg.nhead * cfg.dhead))\n",
    "\n",
    "        self.query_bias    = Parameter(randn(cfg.nhead, cfg.dhead) / sqrt(cfg.dmodel))\n",
    "        self.key_bias      = Parameter(randn(cfg.nhead, cfg.dhead) / sqrt(cfg.dmodel))\n",
    "        self.value_bias    = Parameter(randn(cfg.nhead, cfg.dhead) / sqrt(cfg.dmodel))\n",
    "        self.output_bias   = Parameter(randn(cfg.dmodel)           / sqrt(cfg.nhead * cfg.dhead))\n",
    "\n",
    "    def forward(self, x):\n",
    "        ncontext = x.size(-2)\n",
    "\n",
    "        query = einsum(x, self.query_weight, \"... ncontext dmodel, nhead dmodel dhead -> ... ncontext nhead dhead\")\n",
    "        key   = einsum(x, self.key_weight,   \"... ncontext dmodel, nhead dmodel dhead -> ... ncontext nhead dhead\")\n",
    "        value = einsum(x, self.value_weight, \"... ncontext dmodel, nhead dmodel dhead -> ... ncontext nhead dhead\")\n",
    "        query = query + self.query_bias\n",
    "        key   = key   + self.key_bias\n",
    "        value = value + self.value_bias\n",
    "\n",
    "        attention = einsum(\n",
    "            key,\n",
    "            query,\n",
    "            \"... ncontext_key nhead dhead, ... ncontext_query nhead dhead -> ... nhead ncontext_query ncontext_key\"\n",
    "        )\n",
    "        attention = self.cfg.attention_scale * attention\n",
    "        attention_mask = tril(ones((ncontext, ncontext), dtype=torch.bool, device=device))\n",
    "        attention = where(attention_mask, attention, tensor(self.cfg.mask_value, device=device))\n",
    "        attention = softmax(attention, dim=-1)\n",
    "        \n",
    "        result = einsum(\n",
    "            attention,\n",
    "            value,\n",
    "            \"... nhead ncontext_query ncontext_key, ... ncontext_key nhead dhead -> ... ncontext_query nhead dhead\"\n",
    "        )\n",
    "        output = einsum(result, self.output_weight, \"... ncontext nhead dhead, nhead dhead dmodel -> ... ncontext dmodel\")\n",
    "        output = output + self.output_bias\n",
    "        return output\n",
    "\n",
    "@dataclass\n",
    "class BlockOutput:\n",
    "    output:                  Tensor\n",
    "    activations:             Optional[Dict[str, Tensor]] = None\n",
    "    autoencoder_activations: Optional[Dict[str, Tensor]] = None\n",
    "\n",
    "class TransformerBlock(Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.attention_layer_norm = LayerNorm(cfg.dmodel)\n",
    "        self.mlp_layer_norm = LayerNorm(cfg.dmodel)\n",
    "\n",
    "        self.attention = Attention(cfg)\n",
    "        self.mlp = MLP(cfg)\n",
    "\n",
    "    def forward(self, pre, return_activations=False, return_autoencoder_activations=False, autoencoders=dict()):\n",
    "        assert set(autoencoders.keys()) <= {\"pre\", \"mid\", \"post\", \"attentio\", \"mlp\"}\n",
    "\n",
    "        autoencoder_outputs = dict()\n",
    "\n",
    "        if \"pre\" in autoencoders:\n",
    "            pre, autoencoder_outputs[\"pre\"] = autoencoders[\"pre\"](pre)\n",
    "\n",
    "        attention = self.attention(self.attention_layer_norm(pre))\n",
    "        \n",
    "        if \"attention\" in autoencoders:\n",
    "            attention, autoencoder_outputs[\"attention\"] = autoencoders[\"attention\"](attention)\n",
    "        \n",
    "        mid = pre + attention\n",
    "        \n",
    "        if \"mid\" in autoencoders:\n",
    "            mid, autoencoder_outputs[\"mid\"] = autoencoders[\"mid\"](mid)\n",
    "        \n",
    "        mlp = self.mlp(self.mlp_layer_norm(mid))\n",
    "        \n",
    "        if \"mlp\" in autoencoders:\n",
    "            mlp, autoencoder_outputs[\"mlp\"] = autoencoders[\"mlp\"](mlp)\n",
    "        \n",
    "        post = mid + mlp\n",
    "        \n",
    "        if \"post\" in autoencoders:\n",
    "            post, autoencoder_outputs[\"post\"] = autoencoders[\"post\"](post)\n",
    "\n",
    "        activations = {\"mid\": mid, \"post\": post, \"attention\": attention, \"mlp\": mlp}\n",
    "\n",
    "        return BlockOutput(\n",
    "            output=                  post,\n",
    "            activations=             activations if return_activations else None,\n",
    "            autoencoder_activations= autoencoder_outputs if return_autoencoder_activations else None\n",
    "        )\n",
    "    \n",
    "@dataclass\n",
    "class TransformerOutput:\n",
    "    logits:                  Tensor\n",
    "    activations:             Optional[Dict[Tuple[int, str], Tensor]] = None\n",
    "    autoencoder_activations: Optional[Dict[Tuple[int, str], Tensor]] = None\n",
    "\n",
    "class Transformer(Module):\n",
    "    def __init__(self, cfg, tokenizer=None):\n",
    "        super().__init__()\n",
    "        if isinstance(cfg.activation_function, str):\n",
    "            cfg.activation_function = {\"gelu\": GELU(), \"relu\": ReLU(), \"gelu_new\": NewGELUActivation()}[cfg.activation_function]\n",
    "        \n",
    "        self.cfg = cfg\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        self.embedding = Embedding(cfg.vocab_size, cfg.dmodel)\n",
    "        self.positional_embedding = Embedding(cfg.ncontext, cfg.dmodel)\n",
    "        self.blocks = ModuleList([TransformerBlock(cfg) for _ in range(cfg.nlayers)])\n",
    "        self.unembedding = Linear(cfg.dmodel, cfg.vocab_size)\n",
    "        self.final_layer_norm = LayerNorm(cfg.dmodel)\n",
    "\n",
    "    def forward( self,\n",
    "                 x,\n",
    "                 return_activations=False,\n",
    "                 return_autoencoder_activations=False,\n",
    "                 stop_at_layer=None,\n",
    "                 autoencoders: Dict[Tuple[int, str], Callable] = dict() ):\n",
    "\n",
    "        assert all( layer in range(self.cfg.nlayers) and checkpoint in [\"pre\", \"mid\", \"post\", \"mlp\", \"attention\"]\n",
    "                    for layer, checkpoint in autoencoders.keys() )\n",
    "\n",
    "        if isinstance(x, str):\n",
    "            x = self.tokenizer(x)\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        ncontext = x.size(-2)\n",
    "        x = x + self.positional_embedding(arange(ncontext, device=device))\n",
    "        \n",
    "        activations = dict() if return_activations else None\n",
    "        autoencoder_activations = dict() if return_autoencoder_activations else None\n",
    "        \n",
    "        blocks = self.blocks if stop_at_layer is None else self.blocks[:stop_at_layer]\n",
    "        for layer, block in enumerate(blocks):\n",
    "            pre = x\n",
    "\n",
    "            if layer == 0 and (0, \"pre\") in autoencoders:\n",
    "                pre, autoencoder_activations[(0, \"pre\")] = autoencoders[(0, \"pre\")](pre)\n",
    "\n",
    "            auoencoders_on_layer = { checkpoint: autoencoder\n",
    "                                     for (layer_, checkpoint), autoencoder in autoencoders.items()\n",
    "                                     if layer_ == layer }\n",
    "            output = block( x,\n",
    "                            return_activations=             return_activations,\n",
    "                            return_autoencoder_activations= autoencoder_activations,\n",
    "                            autoencoders=                   auoencoders_on_layer )\n",
    "            x = output.output\n",
    "\n",
    "            if return_activations:\n",
    "                for checkpoint, activation in output.activations.items():\n",
    "                    activations[(layer, checkpoint)] = activation\n",
    "                if layer == 0:\n",
    "                    activations[(0, \"pre\")] = pre\n",
    "\n",
    "            if return_autoencoder_activations:\n",
    "                for checkpoint, activation in output.autoencoder_activations.items():\n",
    "                    activations[(layer, checkpoint)] = activation\n",
    "\n",
    "        x = self.final_layer_norm(x)\n",
    "        x = self.unembedding(x)\n",
    "        \n",
    "        return TransformerOutput(logits=x, activations=activations, autoencoder_activations=autoencoder_activations)\n",
    "\n",
    "    @staticmethod\n",
    "    @inference_mode()\n",
    "    def from_pretrained(pretrained_model_name, test=True, test_atol=1e-4):\n",
    "        theirs = AutoModelForCausalLM.from_pretrained(pretrained_model_name).to(device)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\")\n",
    "\n",
    "        ours = Transformer(TransformerConfig( vocab_size=          tokenizer.vocab_size,\n",
    "                                              ncontext=            theirs.config.max_position_embeddings,\n",
    "                                              dmodel=              theirs.config.hidden_size,\n",
    "                                              dhead=               theirs.config.hidden_size // theirs.config.num_heads,\n",
    "                                              nhead=               theirs.config.num_heads,\n",
    "                                              dmlp=                4 * theirs.config.hidden_size,\n",
    "                                              nlayers=             theirs.config.num_layers,\n",
    "                                              activation_function= theirs.config.activation_function,\n",
    "                                              attention_scale=     1.0,\n",
    "                                              mask_value=          torch.finfo(torch.float).min )).to(device)\n",
    "        \n",
    "        ours.tokenizer = tokenizer\n",
    "\n",
    "        ours.embedding.weight.copy_(theirs.transformer.wte.weight)\n",
    "        ours.positional_embedding.weight.copy_(theirs.transformer.wpe.weight)\n",
    "        ours.unembedding.weight.copy_(theirs.transformer.wte.weight)\n",
    "        zeros_(ours.unembedding.bias)\n",
    "        ours.final_layer_norm.weight.copy_(theirs.transformer.ln_f.weight)\n",
    "        ours.final_layer_norm.bias.copy_(theirs.transformer.ln_f.bias)\n",
    "                    \n",
    "        for layer in range(ours.cfg.nlayers):\n",
    "            ours.blocks[layer].attention_layer_norm.weight.copy_(theirs.transformer.h[layer].ln_1.weight)\n",
    "            ours.blocks[layer].attention_layer_norm.bias.copy_(theirs.transformer.h[layer].ln_1.bias)\n",
    "            ours.blocks[layer].mlp_layer_norm.weight.copy_(theirs.transformer.h[layer].ln_2.weight)\n",
    "            ours.blocks[layer].mlp_layer_norm.bias.copy_(theirs.transformer.h[layer].ln_2.bias)\n",
    "\n",
    "            ours.blocks[layer].attention.query_weight.copy_(theirs.transformer.h[layer].attn.attention.q_proj.weight.reshape(ours.cfg.nhead, ours.cfg.dhead, ours.cfg.dmodel).permute(0, 2, 1))\n",
    "            ours.blocks[layer].attention.key_weight.copy_(theirs.transformer.h[layer].attn.attention.k_proj.weight.reshape(ours.cfg.nhead, ours.cfg.dhead, ours.cfg.dmodel).permute(0, 2, 1))\n",
    "            ours.blocks[layer].attention.value_weight.copy_(theirs.transformer.h[layer].attn.attention.v_proj.weight.reshape(ours.cfg.nhead, ours.cfg.dhead, ours.cfg.dmodel).permute(0, 2, 1))\n",
    "            ours.blocks[layer].attention.output_weight.copy_(theirs.transformer.h[layer].attn.attention.out_proj.weight.reshape(ours.cfg.dmodel, ours.cfg.nhead, ours.cfg.dhead).permute(1, 2, 0))\n",
    "\n",
    "            zeros_(ours.blocks[layer].attention.query_bias)\n",
    "            zeros_(ours.blocks[layer].attention.key_bias)\n",
    "            zeros_(ours.blocks[layer].attention.value_bias)\n",
    "            ours.blocks[layer].attention.output_bias.copy_(theirs.transformer.h[layer].attn.attention.out_proj.bias)\n",
    "\n",
    "            ours.blocks[layer].mlp.up.weight.copy_(theirs.transformer.h[layer].mlp.c_fc.weight)\n",
    "            ours.blocks[layer].mlp.down.weight.copy_(theirs.transformer.h[layer].mlp.c_proj.weight)\n",
    "\n",
    "            ours.blocks[layer].mlp.up.bias.copy_(theirs.transformer.h[layer].mlp.c_fc.bias)\n",
    "            ours.blocks[layer].mlp.down.bias.copy_(theirs.transformer.h[layer].mlp.c_proj.bias)\n",
    "\n",
    "        if test:\n",
    "            print(\"Testing that the model behaves the same as the library model... \", end=\"\", flush=True)\n",
    "            inputs = randint(0, ours.cfg.vocab_size, (64, 64), device=device)\n",
    "            assert allclose(ours(inputs).logits, theirs(inputs).logits, atol=test_atol), \"Tests failed!\"\n",
    "            print(\"Test passed!\")\n",
    "\n",
    "        return ours\n",
    "    \n",
    "        \"\"\"\n",
    "        theirs = HookedTransformer.from_pretrained(pretrained_model_name)\n",
    "        \n",
    "        ours = Transformer(TransformerConfig( vocab_size=theirs.tokenizer.vocab_size,\n",
    "                                      ncontext=theirs.cfg.n_ctx,\n",
    "                                      dmodel=theirs.cfg.d_model,\n",
    "                                      dhead=theirs.cfg.d_head,\n",
    "                                      nhead=theirs.cfg.n_heads,\n",
    "                                      dmlp=theirs.cfg.d_mlp,\n",
    "                                      nlayers=theirs.cfg.n_layers,\n",
    "                                      activation_function=theirs.cfg.act_fn ))\n",
    "\n",
    "        ours.tokenizer = theirs.tokenizer\n",
    "\n",
    "        with torch.no_grad():\n",
    "            ours.embedding.weight.copy_(theirs.embed.W_E)\n",
    "            ours.positional_embedding.weight.copy_(theirs.pos_embed.W_pos)\n",
    "            ours.unembedding.weight.copy_(theirs.unembed.W_U.transpose(0, 1))\n",
    "            ours.unembedding.bias.copy_(theirs.unembed.b_U)\n",
    "            \n",
    "            for layer in range(ours.cfg.nlayers):\n",
    "                ours.blocks[layer].attention.query_weight.copy_(theirs.blocks[layer].attn.W_Q)\n",
    "                ours.blocks[layer].attention.key_weight.copy_(theirs.blocks[layer].attn.W_K)\n",
    "                ours.blocks[layer].attention.value_weight.copy_(theirs.blocks[layer].attn.W_V)\n",
    "                ours.blocks[layer].attention.output_weight.copy_(theirs.blocks[layer].attn.W_O)\n",
    "\n",
    "                ours.blocks[layer].attention.query_bias.copy_(theirs.blocks[layer].attn.b_Q)\n",
    "                ours.blocks[layer].attention.key_bias.copy_(theirs.blocks[layer].attn.b_K)\n",
    "                ours.blocks[layer].attention.value_bias.copy_(theirs.blocks[layer].attn.b_V)\n",
    "                ours.blocks[layer].attention.output_bias.copy_(theirs.blocks[layer].attn.b_O)\n",
    "\n",
    "                ours.blocks[layer].mlp.up.weight.copy_(theirs.blocks[layer].mlp.W_in.transpose(0, 1))\n",
    "                ours.blocks[layer].mlp.down.weight.copy_(theirs.blocks[layer].mlp.W_out.transpose(0, 1))\n",
    "\n",
    "                ours.blocks[layer].mlp.up.bias.copy_(theirs.blocks[layer].mlp.b_in)\n",
    "                ours.blocks[layer].mlp.down.bias.copy_(theirs.blocks[layer].mlp.b_out)\n",
    "\n",
    "        return ours\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing that the model behaves the same as the library model... Test passed!\n"
     ]
    }
   ],
   "source": [
    "model = Transformer.from_pretrained(\"roneneldan/TinyStories-1M\", test=True).to(device)\n",
    "theirs = AutoModelForCausalLM.from_pretrained(\"roneneldan/TinyStories-1M\")\n",
    "theirs.eval()\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_val_test_split(dataset, val_size=0.1, test_size=0.1):\n",
    "#     dataset = dataset.train_test_split(test_size=val_size+test_size)\n",
    "#     val_test_dataset = dataset[\"test\"].train_test_split(test_size = val_size / (val_size + test_size))\n",
    "#     return DatasetDict({ \"train\": dataset[\"train\"],\n",
    "#                          \"val\":   val_test_dataset[\"train\"],\n",
    "#                          \"test\":  val_test_dataset[\"test\"] })\n",
    "\n",
    "def make_tokens_dataset(text_dataset, tokenizer):\n",
    "    tokens_dataset = text_dataset.map(lambda datapoint: tokenizer(datapoint[\"text\"]))\n",
    "    tokens_dataset = tokens_dataset.remove_columns([\"text\", \"attention_mask\"])\n",
    "    tokens_dataset.set_format(\"torch\")\n",
    "    return tokens_dataset\n",
    "\n",
    "def all_equal(xs):\n",
    "    return all(current == next for current, next in pairwise(xs))\n",
    "\n",
    "class DictTensorDataset(Dataset):\n",
    "    def __init__(self, tensors: Dict[Any, Tensor]):\n",
    "        assert all_equal(tensor.size(0) for tensor in tensors.values()), \"Size mismatch between tensors\"\n",
    "        self.tensors = tensors\n",
    "\n",
    "    def __len__(self):\n",
    "        return next(iter(self.tensors.values())).size(0)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {key: tensor[index] for key, tensor in self.tensors.items()}\n",
    "\n",
    "def dict_collate_fn(dicts: Iterable[Dict[Any, Tensor]]):\n",
    "    if not isinstance(dicts, list):\n",
    "        dicts = list(dicts)\n",
    "\n",
    "    collated = { key: empty(len(dicts), *tensor.shape)\n",
    "                 for key, tensor in dicts[0].items() }\n",
    "\n",
    "    for i, dict in enumerate(dicts):\n",
    "        for key, tensor in dict.items():\n",
    "            collated[key][i, :] = tensor\n",
    "\n",
    "    return collated\n",
    "\n",
    "def english_join(xs, comma=\", \", and_=\" and \", oxford_and=\", and \"):\n",
    "    xs = list(xs)\n",
    "    if len(xs) == 0:\n",
    "        return \"\"\n",
    "    if len(xs) == 1:\n",
    "        return xs[0]\n",
    "    if len(xs) == 2:\n",
    "        return xs[0] + and_ + xs[1]\n",
    "    return comma.join(xs[:-1]) + oxford_and + xs[-1]\n",
    "\n",
    "def activations_data_filename(storage_directory, checkpoint):\n",
    "        assert storage_directory is not None\n",
    "        layer, checkpoint = checkpoint\n",
    "        return f\"{storage_directory}/layer{layer}-{checkpoint}.dat\"\n",
    "\n",
    "def activations_shape_filename(storage_directory, checkpoint):\n",
    "    assert storage_directory is not None\n",
    "    layer, checkpoint = checkpoint\n",
    "    return f\"{storage_directory}/layer{layer}-{checkpoint}-shape.pickle\"\n",
    "\n",
    "def load_activations_dataset_from_disk(storage_directory, checkpoints):\n",
    "    checkpoints_on_disk = [ checkpoint\n",
    "                            for checkpoint in checkpoints\n",
    "                            if     isfile(activations_data_filename( storage_directory, checkpoint))\n",
    "                               and isfile(activations_shape_filename(storage_directory, checkpoint))]\n",
    "    \n",
    "    if len(checkpoints_on_disk) > 0:\n",
    "        print(\"Loading activations for\", english_join(f\"layer{layer}-{checkpoint}\" for layer, checkpoint in checkpoints_on_disk), \"from disk.\")\n",
    "\n",
    "    activations_storage = {}\n",
    "    for checkpoint in checkpoints_on_disk:\n",
    "        with open(activations_shape_filename(storage_directory, checkpoint), \"wb\") as shape_file:\n",
    "            shape = pickle.load(shape_file)\n",
    "\n",
    "        activations_storage[checkpoint] = FloatTensor(Storage.from_file(\n",
    "            activations_data_filename(storage_directory, checkpoint),\n",
    "            shared=True,\n",
    "            size=prod(shape)\n",
    "        )).reshape(shape)\n",
    "\n",
    "    return activations_storage\n",
    "\n",
    "def make_empty_activations_dataset_on_disk(storage_directory, checkpoints, shape):\n",
    "    activations_storage = {}\n",
    "    for checkpoint in checkpoints:\n",
    "        activations_storage[checkpoint] = FloatTensor(Storage.from_file(\n",
    "            activations_data_filename(storage_directory, checkpoint),\n",
    "            shared=True,\n",
    "            size=prod(shape)\n",
    "        )).reshape(shape)\n",
    "\n",
    "    return activations_storage\n",
    "\n",
    "def finish_storing_activations_dataset_on_disk(storage_directory, activations_storage):\n",
    "    for checkpoint, activations in activations_storage.items():\n",
    "        shape_filename = activations_shape_filename(storage_directory, checkpoint)\n",
    "        if not isfile(shape_filename):\n",
    "            with open(shape_filename, \"wb\") as shape_file:\n",
    "                pickle.dump(activations.shape, shape_file)\n",
    "\n",
    "@inference_mode()\n",
    "def make_activation_dataset(model, tokens_dataset, checkpoints, on_disk=False, storage_directory=None, _tqdm=True):\n",
    "    model.eval()\n",
    "\n",
    "    activations_storage = {}\n",
    "\n",
    "    if on_disk:\n",
    "        activations_storage = load_activations_dataset_from_disk(storage_directory, checkpoints)\n",
    "        already_computed_checkpoints = list(activations_storage.keys())\n",
    "        checkpoints = [checkpoint for checkpoint in checkpoints if checkpoint not in already_computed_checkpoints]\n",
    "\n",
    "    if list(checkpoints) != []:\n",
    "        total_ntokens = sum(len(data[\"input_ids\"]) for data in (tqdm(tokens_dataset) if _tqdm else tokens_dataset))\n",
    "        shape = (total_ntokens, model.cfg.dmodel)\n",
    "\n",
    "        if on_disk:\n",
    "            activations_storage.update(make_empty_activations_dataset_on_disk(storage_directory, checkpoints))\n",
    "        else:\n",
    "            activations_storage.update({checkpoint: empty(shape) for checkpoint in checkpoints})\n",
    "\n",
    "        i = 0\n",
    "        for i_story, data in enumerate(tqdm(tokens_dataset)) if _tqdm else enumerate(tokens_dataset):\n",
    "            tokens = data[\"input_ids\"].to(device)\n",
    "            output = model(tokens, return_activations=True, stop_at_layer=1+max(layer for layer, _ in checkpoints))\n",
    "            for checkpoint in checkpoints:\n",
    "                activations_storage[checkpoint][i:i+len(tokens), :] = output.activations[checkpoint]\n",
    "            if i_story % 10_000 == 0:\n",
    "                gc.collect() # for some reason, we were getting out of memory (out of ram, not out of gpu ram)\n",
    "            i += len(tokens)\n",
    "        assert i == total_ntokens\n",
    "\n",
    "    if on_disk:\n",
    "        finish_storing_activations_dataset_on_disk(storage_directory, activations_storage)\n",
    "\n",
    "    return DictTensorDataset(activations_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration roneneldan--TinyStories-a62fc98e062666ca\n",
      "Reusing dataset parquet (/home/paperspace/.cache/huggingface/datasets/roneneldan___parquet/roneneldan--TinyStories-a62fc98e062666ca/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654e40c0a4154c4ba13ec8ffb06c275a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/paperspace/.cache/huggingface/datasets/roneneldan___parquet/roneneldan--TinyStories-a62fc98e062666ca/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-f83e8c8f1f8d1604.arrow\n",
      "Loading cached processed dataset at /home/paperspace/.cache/huggingface/datasets/roneneldan___parquet/roneneldan--TinyStories-a62fc98e062666ca/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-a7c2d5621cccac94.arrow\n"
     ]
    }
   ],
   "source": [
    "text_dataset             = load_dataset(\"roneneldan/TinyStories\")\n",
    "tokens_dataset           = make_tokens_dataset(text_dataset, model.tokenizer)\n",
    "test_tokens_dataset      = tokens_dataset[\"validation\"]\n",
    "train_val_tokens_dataset = tokens_dataset[\"train\"].train_test_split(test_size=0.1)\n",
    "train_tokens_dataset     = train_val_tokens_dataset[\"train\"]\n",
    "val_tokens_dataset       = train_val_tokens_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 1907747/1907747 [03:39<00:00, 8679.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading activations for layer0-mlp from disk.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 211972/211972 [00:24<00:00, 8719.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading activations for layer0-mlp from disk.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_activations_dataset = make_activation_dataset(model, train_tokens_dataset, checkpoints=[(0, \"mlp\")], on_disk=True, storage_directory=\"/home/paperspace/activations/train/\")\n",
    "train_activations_dataloader = DataLoader(train_activations_dataset, batch_size=4096,   collate_fn=dict_collate_fn)\n",
    "\n",
    "val_activations_dataset = make_activation_dataset(model, val_tokens_dataset, checkpoints=[(0, \"mlp\")], on_disk=True, storage_directory=\"/home/paperspace/activations/val/\")\n",
    "val_activations_dataloader = DataLoader(val_activations_dataset, batch_size=4096, collate_fn=dict_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseAutoencoder(Module):\n",
    "    def __init__(self, d, dhidden, activation_function=ReLU()):\n",
    "        super().__init__()\n",
    "        self.pre_bias = Parameter(zeros(d))\n",
    "        self.up = Linear(d, dhidden)\n",
    "        self.activation_function = activation_function\n",
    "        self.down = Linear(dhidden, d)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = self.up(x - self.pre_bias)\n",
    "        hidden = self.activation_function(hidden)\n",
    "        output = self.down(hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    @no_grad()\n",
    "    def make_decoder_weight_unit_norm(self):\n",
    "        self.down.weight /= self.down.weight.norm(dim=-1, keepdim=True)\n",
    "        normalized_weight = self.down.weight / self.down.weight.norm(dim=-1, keepdim=True)\n",
    "        grad_proj = normalized_weight * (normalized_weight * self.down.weight.grad).sum(dim=-1, keepdim=True)\n",
    "        self.down.weight.data = normalized_weight\n",
    "        self.down.weight.grad -= grad_proj\n",
    "\n",
    "class L1Penalty(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.norm(dim=-1, p=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sparse_autoencoder( sparse_autoencoders,\n",
    "                              activations_dataloader,\n",
    "                              checkpoint,\n",
    "                              epochs,\n",
    "                              sparsity_penalty_weights,\n",
    "                              learning_rates,\n",
    "                              reconstruction_loss_fn=MSELoss(),\n",
    "                              sparsity_penalty_fn=L1Penalty(),\n",
    "                              optimizer=None,\n",
    "                              epoch_tqdm=True,\n",
    "                              batch_tqdm=False,\n",
    "                              plot=True,\n",
    "                              plot_filenames=None ):\n",
    "    \n",
    "    nb_autoencoders = len(sparse_autoencoders)   \n",
    "    \n",
    "    assert len(sparsity_penalty_weights) == nb_autoencoders\n",
    "    assert len(learning_rates) == nb_autoencoders\n",
    "    if plot_filenames is not None:\n",
    "        assert len(plot_filenames) == nb_autoencoders\n",
    "\n",
    "    optimizers = [AdamW(sparse_autoencoders[i].parameters(), lr=learning_rates[i]) for i in range(nb_autoencoders)]\n",
    "    \n",
    "    reconstruction_loss_histories = [[] for _ in range(len(sparse_autoencoders))]\n",
    "    sparsity_penalty_histories    = [[] for _ in range(len(sparse_autoencoders))]\n",
    "    for epoch in tqdm(range(epochs)) if epoch_tqdm else range(epochs):\n",
    "        for activations in tqdm(activations_dataloader) if batch_tqdm else activations_dataloader:\n",
    "            for i in range(nb_autoencoders):\n",
    "                activations = activations[checkpoint].detach().to(device)\n",
    "                reconstructed, hidden = sparse_autoencoders[i](activations)\n",
    "                reconstruction_loss = reconstruction_loss_fn(reconstructed, activations)\n",
    "                sparsity_penalty = sparsity_penalty_fn(hidden)\n",
    "                loss = reconstruction_loss + sparsity_penalty_weights[i] * sparsity_penalty\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                sparse_autoencoders[i].make_decoder_weight_unit_norm()\n",
    "                optimizers[i].step()\n",
    "                reconstruction_loss_histories[i].append(reconstruction_loss.item())\n",
    "                sparsity_penalty_histories[i].append(sparsity_penalty.item())\n",
    "\n",
    "    if plot:\n",
    "        for i in range(nb_autoencoders):\n",
    "            plt.title(f\"Sparse autoencoder training loss, lr={learning_rates[i]}, sparsity_penalty_weight={sparsity_penalty_weights[i]}\")\n",
    "            plt.xlabel(\"training steps\")\n",
    "            plt.ylabel(\"loss\")\n",
    "            plt.yscale(\"log\")\n",
    "            plt.plot(reconstruction_loss_histories[i], label=\"reconstruction loss\")\n",
    "            plt.plot(sparsity_penalty_histories[i], label=\"sparsity penalty\")\n",
    "            plt.legend()\n",
    "            \n",
    "            if plot_filenames is not None:\n",
    "                plt.savefig(plot_filenames[i])\n",
    "            plt.show()\n",
    "\n",
    "    return { \"reconstruction_loss_histories\": reconstruction_loss_histories,\n",
    "             \"sparsity_penalty_histories\": sparsity_penalty_histories }\n",
    "\n",
    "@inference_mode()\n",
    "def test_sparse_autoencoder( model,\n",
    "                             autoencoders,\n",
    "                             tokens_dataset,\n",
    "                             activations_dataloader,\n",
    "                             sparsity_penalty_fn=L1Penalty(),\n",
    "                             reconstruction_loss_fn=MSELoss(),\n",
    "                             whole_model_reconstruction_loss_fn=KLDivLoss(),\n",
    "                             test_whole_model=True,\n",
    "                             _tqdm=True ):\n",
    "    \n",
    "    sparsity_penalties    = dict()\n",
    "    reconstruction_losses = dict()\n",
    "    for checkpoint, autoencoder in autoencoders.items():\n",
    "        sparsity_penalties   [checkpoint] = 0\n",
    "        reconstruction_losses[checkpoint] = 0\n",
    "        for activations in tqdm(activations_dataloader) if _tqdm else activations_dataloader:\n",
    "            acts = activations[checkpoint].to(device)\n",
    "            reconstructed, hidden = autoencoder(acts)\n",
    "            sparsity_penalties   [checkpoint] += sparsity_penalty_fn(hidden)\n",
    "            reconstruction_losses[checkpoint] += reconstruction_loss_fn(reconstructed, acts)\n",
    "        sparsity_penalties   [checkpoint] /= len(activations_dataloader)\n",
    "        reconstruction_losses[checkpoint] /= len(activations_dataloader)\n",
    "\n",
    "    if test_whole_model:\n",
    "        whole_model_reconstruction_loss = 0.0\n",
    "        for tokens in tqdm(tokens_dataset) if _tqdm else tokens_dataset:\n",
    "            tokens = tokens[\"input_ids\"].to(device)\n",
    "            logits = model(tokens).logits\n",
    "            logits_with_autoencoders = model(tokens, autoencoders=autoencoders).logits\n",
    "            whole_model_reconstruction_loss += whole_model_reconstruction_loss_fn(logits_with_autoencoders, logits)\n",
    "        whole_model_reconstruction_loss_fn /= len(tokens_dataset)\n",
    "\n",
    "    result = { \"reconstruction_losses\": reconstruction_losses,\n",
    "                \"sparsity_penalties\": sparsity_penalties }\n",
    "    if test_whole_model:\n",
    "        result[\"whole_models_reconstruction_loss\"] = whole_model_reconstruction_loss\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2223,  0.1561,  0.1795,  ...,  0.0575,  0.1452,  0.0394],\n",
       "        [-0.0053,  0.1690,  0.0861,  ...,  0.1094, -0.1616, -0.0469],\n",
       "        [-0.0093, -0.0714, -0.0252,  ...,  0.1034, -0.0625, -0.1157],\n",
       "        ...,\n",
       "        [-0.0499, -0.0578,  0.0462,  ..., -0.1591, -0.0468,  0.0920],\n",
       "        [ 0.1257, -0.0305, -0.0961,  ..., -0.2037,  0.0103,  0.0683],\n",
       "        [ 0.0522, -0.1157,  0.1564,  ..., -0.0299, -0.1015,  0.0344]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_activations_dataloader.dataset.tensors[(0, \"mlp\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse_autoencoder = torch.load(\"/home/paperspace/disfunctional_autoencoder.tch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_many(xs):\n",
    "    if not isinstance(xs, list):\n",
    "        xs = list(xs)\n",
    "    if xs == []:\n",
    "        return []\n",
    "    n = len(xs[0])\n",
    "    assert all(len(x) == n for x in xs)\n",
    "    return tuple([x[i] for x in xs] for i in range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /home/paperspace/autoencoders/loss_plots/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = (0, \"mlp\")\n",
    "sparse_autoencoders = []\n",
    "learning_rates = []\n",
    "sparsity_penalty_weights = []\n",
    "plot_filenames = []\n",
    "for dhidden_multiplier in [1, 2, 4, 8, 16, 32, 64, 128, 258, 512, 1024]:\n",
    "    for sparsity_penalty_weight in [1e-1, 5e-2, 1e-2, 5e-3, 1e-3, 5e-4, 1e-4, 5e-5, 1e-5, 5e-6, 1e-6]:\n",
    "        for learning_rate in [1e-3, 1e-4]:\n",
    "            dmodel = model.cfg.dmodel\n",
    "            dhidden = dmodel * dhidden_multiplier\n",
    "            sparse_autoencoders.append(SparseAutoencoder(dmodel, dhidden).to(device))\n",
    "            learning_rates.append(learning_rate)\n",
    "            sparsity_penalty_weights.append(sparsity_penalty_weight)\n",
    "            plot_filenames.append( f\"/home/paperspace/autoencoders/loss_plots/layer{checkpoint[0]}-{checkpoint[1]}\"\\\n",
    "                                   f\"-dhidden-{dhidden}-sparsity-penalty-{sparsity_penalty_weight}-lr-{learning_rate}.png\" )\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                | 0/103672 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 103672/103672 [53:14<00:00, 32.45it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sparse_autoencoder = SparseAutoencoder(model.cfg.dmodel, 4*model.cfg.dmodel).to(device)\n",
    "training_log = train_sparse_autoencoder( sparse_autoencoder,\n",
    "                                         train_activations_dataloader,\n",
    "                                         checkpoint=(0, \"mlp\"),\n",
    "                                         epochs=1,\n",
    "                                         lr=1e-3,\n",
    "                                         sparsity_penalty_weight=1e-4,\n",
    "                                         epoch_tqdm=False,\n",
    "                                         batch_tqdm=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/11532 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 11532/11532 [04:18<00:00, 44.63it/s]\n",
      "  0%|                                                | 0/211972 [00:00<?, ?it/s]/home/paperspace/.local/lib/python3.9/site-packages/torch/nn/functional.py:2904: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n",
      " 24%|████████▋                           | 51435/211972 [09:10<28:57, 92.41it/s]"
     ]
    }
   ],
   "source": [
    "test_results = test_sparse_autoencoder( model,\n",
    "                                        {(0, \"mlp\"): sparse_autoencoder},\n",
    "                                        tokens_dataset=val_tokens_dataset,\n",
    "                                        activations_dataloader=val_activations_dataloader )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training the model - don't look at it, we will only train the model from scratch if we have time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_token_logits(model, seq):\n",
    "    return model(seq)[..., -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repetition_dataset(vocab_size, ncontext, size):\n",
    "    assert ncontext % 2 == 1\n",
    "    data = randint(vocab_size, (size, (ncontext + 1) // 2), device=device)\n",
    "    data = data.repeat(1, 2)\n",
    "    return TensorDataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_cross_entropy_loss(pred, true):\n",
    "    return cross_entropy(pred.transpose(1, -1), true.transpose(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, epochs, loss_fn=transformer_cross_entropy_loss, lr=1e-3, epoch_tqdm=True, batch_tqdm=False, plot_loss=True):\n",
    "    model.train()\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "    \n",
    "    loss_history = []\n",
    "    for epoch in tqdm(range(epochs)) if epoch_tqdm else range(epochs):\n",
    "        for x, in tqdm(dataloader) if batch_tqdm else dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(model(x[..., :-1]), x[..., 1:])\n",
    "            loss_history.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    if plot_loss:\n",
    "        plt.title(\"training_loss\")\n",
    "        plt.xlabel(\"training iteration\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.yscale(\"log\")\n",
    "        plt.plot(loss_history)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = TransformerConfig(vocab_size=10, ncontext=17, dmodel=16, dhead=4, nhead=4, dmlp=32, nlayers=2)\n",
    "train_dataloader = DataLoader(repetition_dataset(vocab_size=cfg.vocab_size, ncontext=cfg.ncontext, size=500_000), batch_size=64, shuffle=True)\n",
    "model = Transformer(cfg).to(device)\n",
    "train(model, train_dataloader, epochs=1, batch_tqdm=True, epoch_tqdm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(repetition_dataset(vocab_size=cfg.vocab_size, ncontext=cfg.ncontext, size=1_000), batch_size=64, shuffle=True)\n",
    "x, = next(iter(test_dataloader))\n",
    "model(x[0, :2])\n",
    "print(x.shape)\n",
    "print(model(x[..., :-1]).argmax(-1)[0, ...])\n",
    "print(x[..., 1:][0, ...])\n",
    "print(x[..., :-1][0, ...])\n",
    "print(transformer_cross_entropy_loss(model(x[..., :-1]), x[..., 1:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
